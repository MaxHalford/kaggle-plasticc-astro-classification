{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You only have to run the following cell once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-920c5b06ca78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     (\n\u001b[1;32m     14\u001b[0m         \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/training_set.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test_set.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     ),\n\u001b[1;32m     17\u001b[0m     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m     \"\"\"\n\u001b[1;32m    813\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtypes = {\n",
    "    'object_id': np.uint32,\n",
    "    'mjd': np.float32,\n",
    "    'passband': np.uint8,\n",
    "    'flux': np.float32,\n",
    "    'flux_err': np.float32,\n",
    "    'detected': bool\n",
    "}\n",
    "lcs = pd.concat(\n",
    "    (\n",
    "        pd.read_csv('data/training_set.csv', dtype=dtypes),\n",
    "        pd.read_csv('data/test_set.csv', dtype=dtypes)\n",
    "    ),\n",
    "    sort=False,\n",
    "    ignore_index=True\n",
    ")\n",
    "lcs.to_hdf('data/data.h5', 'light_curves')\n",
    "\n",
    "dtypes = {\n",
    "    'object_id': np.uint32\n",
    "}\n",
    "df = pd.concat(\n",
    "    (\n",
    "        pd.read_csv('data/training_set_metadata.csv', dtype=dtypes),\n",
    "        pd.read_csv('data/test_set_metadata.csv', dtype=dtypes)\n",
    "    ),\n",
    "    sort=False,\n",
    "    ignore_index=True\n",
    ")\n",
    "df['is_train'] = df['target'].notnull()\n",
    "df.to_hdf('data/data.h5', 'meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the HDF5 files (it weights much less than the initial files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "lcs = pd.read_hdf('data/data.h5', 'light_curves')\n",
    "df = pd.read_hdf('data/data.h5', 'meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mjd_to_unix(mjd):\n",
    "    return (mjd - 40587) * 86400\n",
    "\n",
    "#lcs['mjd'] = pd.to_datetime(lcs['mjd'].apply(mjd_to_unix), unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object/passband features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['bfr_0', 'bfr_1', 'bfr_2', 'bfr_3', 'bfr_4', 'bfr_5',\n       'flux_diff_kurtosis_0', 'flux_diff_kurtosis_1', 'flux_diff_kurtosis_2',\n       'flux_diff_kurtosis_3',\n       ...\n       'flux_ptp_2', 'flux_ptp_3', 'flux_ptp_4', 'flux_ptp_5', 'flux_skew_0',\n       'flux_skew_1', 'flux_skew_2', 'flux_skew_3', 'flux_skew_4',\n       'flux_skew_5'],\n      dtype='object', length=114)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-18f4dbb86434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassbands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6324\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6325\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 6326\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   6327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6328\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6339\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   6340\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6341\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   6342\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                          validate=validate)\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         llabels, rlabels = items_overlap_with_suffix(ldata.items, lsuf,\n\u001b[0;32m--> 573\u001b[0;31m                                                      rdata.items, rsuf)\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mlindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mleft_indexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mitems_overlap_with_suffix\u001b[0;34m(left, lsuffix, right, rsuffix)\u001b[0m\n\u001b[1;32m   5242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5243\u001b[0m             raise ValueError('columns overlap but no suffix specified: '\n\u001b[0;32m-> 5244\u001b[0;31m                              '{rename}'.format(rename=to_rename))\n\u001b[0m\u001b[1;32m   5245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5246\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['bfr_0', 'bfr_1', 'bfr_2', 'bfr_3', 'bfr_4', 'bfr_5',\n       'flux_diff_kurtosis_0', 'flux_diff_kurtosis_1', 'flux_diff_kurtosis_2',\n       'flux_diff_kurtosis_3',\n       ...\n       'flux_ptp_2', 'flux_ptp_3', 'flux_ptp_4', 'flux_ptp_5', 'flux_skew_0',\n       'flux_skew_1', 'flux_skew_2', 'flux_skew_3', 'flux_skew_4',\n       'flux_skew_5'],\n      dtype='object', length=114)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "stats = pd.read_csv('data/features/flux_stats.csv')\\\n",
    "          .pivot(index='object_id', columns='passband')\\\n",
    "          .astype(np.float32)\n",
    "\n",
    "# Collapse the column names\n",
    "names = stats.columns.get_level_values(0)\n",
    "passbands = stats.columns.get_level_values(1).astype(str)\n",
    "stats.columns = ['_'.join(pair) for pair in zip(names, passbands)]\n",
    "\n",
    "stats['flux_diff_min_0'].replace(np.inf, stats['flux_diff_min_0'][stats['flux_diff_min_0'] != np.inf].max(), inplace=True)\n",
    "\n",
    "df = df.join(stats, on='object_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2 = pd.read_csv('data/features/flux_stats2.csv').set_index('object_id')\n",
    "df = df.join(stats2, on='object_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>decl</th>\n",
       "      <th>gal_l</th>\n",
       "      <th>gal_b</th>\n",
       "      <th>ddf</th>\n",
       "      <th>hostgal_specz</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>distmod</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_ptp_4</th>\n",
       "      <th>flux_ptp_5</th>\n",
       "      <th>flux_skew_0</th>\n",
       "      <th>flux_skew_1</th>\n",
       "      <th>flux_skew_2</th>\n",
       "      <th>flux_skew_3</th>\n",
       "      <th>flux_skew_4</th>\n",
       "      <th>flux_skew_5</th>\n",
       "      <th>count</th>\n",
       "      <th>passband_n_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>615</td>\n",
       "      <td>349.046051</td>\n",
       "      <td>-61.943836</td>\n",
       "      <td>320.796530</td>\n",
       "      <td>-51.753706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>804.138245</td>\n",
       "      <td>801.003235</td>\n",
       "      <td>0.125827</td>\n",
       "      <td>0.404755</td>\n",
       "      <td>0.331063</td>\n",
       "      <td>0.285492</td>\n",
       "      <td>0.194883</td>\n",
       "      <td>0.121948</td>\n",
       "      <td>352</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>713</td>\n",
       "      <td>53.085938</td>\n",
       "      <td>-27.784405</td>\n",
       "      <td>223.525509</td>\n",
       "      <td>-54.460748</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8181</td>\n",
       "      <td>1.6267</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>45.4063</td>\n",
       "      <td>...</td>\n",
       "      <td>22.114735</td>\n",
       "      <td>28.982050</td>\n",
       "      <td>0.254446</td>\n",
       "      <td>-0.085494</td>\n",
       "      <td>-0.022066</td>\n",
       "      <td>-0.162664</td>\n",
       "      <td>-0.062403</td>\n",
       "      <td>0.212294</td>\n",
       "      <td>350</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>33.574219</td>\n",
       "      <td>-6.579593</td>\n",
       "      <td>170.455585</td>\n",
       "      <td>-61.548219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>40.2561</td>\n",
       "      <td>...</td>\n",
       "      <td>46.996292</td>\n",
       "      <td>66.469872</td>\n",
       "      <td>0.349431</td>\n",
       "      <td>0.457635</td>\n",
       "      <td>2.315707</td>\n",
       "      <td>2.584661</td>\n",
       "      <td>2.462542</td>\n",
       "      <td>1.630520</td>\n",
       "      <td>330</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>745</td>\n",
       "      <td>0.189873</td>\n",
       "      <td>-45.586655</td>\n",
       "      <td>328.254458</td>\n",
       "      <td>-68.969298</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>1.1523</td>\n",
       "      <td>40.7951</td>\n",
       "      <td>...</td>\n",
       "      <td>199.127579</td>\n",
       "      <td>151.762680</td>\n",
       "      <td>1.980815</td>\n",
       "      <td>6.817995</td>\n",
       "      <td>5.534683</td>\n",
       "      <td>3.650356</td>\n",
       "      <td>3.382600</td>\n",
       "      <td>3.083716</td>\n",
       "      <td>351</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1124</td>\n",
       "      <td>352.711273</td>\n",
       "      <td>-63.823658</td>\n",
       "      <td>316.922299</td>\n",
       "      <td>-51.059403</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>40.4166</td>\n",
       "      <td>...</td>\n",
       "      <td>160.143936</td>\n",
       "      <td>120.018127</td>\n",
       "      <td>-0.324207</td>\n",
       "      <td>2.315295</td>\n",
       "      <td>2.995322</td>\n",
       "      <td>3.509344</td>\n",
       "      <td>3.802308</td>\n",
       "      <td>3.560348</td>\n",
       "      <td>352</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id          ra       decl       gal_l      gal_b  ddf  \\\n",
       "0        615  349.046051 -61.943836  320.796530 -51.753706    1   \n",
       "1        713   53.085938 -27.784405  223.525509 -54.460748    1   \n",
       "2        730   33.574219  -6.579593  170.455585 -61.548219    1   \n",
       "3        745    0.189873 -45.586655  328.254458 -68.969298    1   \n",
       "4       1124  352.711273 -63.823658  316.922299 -51.059403    1   \n",
       "\n",
       "   hostgal_specz  hostgal_photoz  hostgal_photoz_err  distmod  \\\n",
       "0         0.0000          0.0000              0.0000      NaN   \n",
       "1         1.8181          1.6267              0.2552  45.4063   \n",
       "2         0.2320          0.2262              0.0157  40.2561   \n",
       "3         0.3037          0.2813              1.1523  40.7951   \n",
       "4         0.1934          0.2415              0.0176  40.4166   \n",
       "\n",
       "         ...          flux_ptp_4  flux_ptp_5  flux_skew_0  flux_skew_1  \\\n",
       "0        ...          804.138245  801.003235     0.125827     0.404755   \n",
       "1        ...           22.114735   28.982050     0.254446    -0.085494   \n",
       "2        ...           46.996292   66.469872     0.349431     0.457635   \n",
       "3        ...          199.127579  151.762680     1.980815     6.817995   \n",
       "4        ...          160.143936  120.018127    -0.324207     2.315295   \n",
       "\n",
       "   flux_skew_2  flux_skew_3  flux_skew_4  flux_skew_5  count  \\\n",
       "0     0.331063     0.285492     0.194883     0.121948    352   \n",
       "1    -0.022066    -0.162664    -0.062403     0.212294    350   \n",
       "2     2.315707     2.584661     2.462542     1.630520    330   \n",
       "3     5.534683     3.650356     3.382600     3.083716    351   \n",
       "4     2.995322     3.509344     3.802308     3.560348    352   \n",
       "\n",
       "   passband_n_unique  \n",
       "0                  6  \n",
       "1                  6  \n",
       "2                  6  \n",
       "3                  6  \n",
       "4                  6  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['is_train', 'target', 'hostgal_specz']\n",
    "\n",
    "train = df.query('is_train == True').set_index('object_id')\n",
    "test = df.query('is_train == False').set_index('object_id')\n",
    "\n",
    "X_train = train.drop(columns=to_drop)\n",
    "y_train = train['target'].apply(lambda x: f'class_{int(x)}').astype('category')\n",
    "X_test = test.drop(columns=to_drop)\n",
    "submission = pd.DataFrame(0.0, index=test.index, columns=y_train.cat.categories)\n",
    "submission['class_99'] = 0.0\n",
    "\n",
    "class_weights = {c: 1 for c in y_train.cat.categories}\n",
    "class_weights['class_64'] = 2\n",
    "class_weights['class_15'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_train.columns) == len(X_test.columns)\n",
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_train) == len(w_train)\n",
    "assert len(X_test) == 3492890\n",
    "assert len(submission) == 3492890"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galactic objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the galactic objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gal = X_train[X_train['hostgal_photoz'] == 0]\n",
    "y_train_gal = y_train[X_train['hostgal_photoz'] == 0]\n",
    "X_test_gal = X_test[X_test['hostgal_photoz'] == 0]\n",
    "\n",
    "class_to_int = {c: i for i, c in enumerate(y_train_gal.unique())}\n",
    "int_to_class = {i: c for c, i in class_to_int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.124001\tval's multi_logloss: 0.231071\n",
      "[100]\tfit's multi_logloss: 0.021045\tval's multi_logloss: 0.133079\n",
      "[150]\tfit's multi_logloss: 0.00448423\tval's multi_logloss: 0.118232\n",
      "[200]\tfit's multi_logloss: 0.00113722\tval's multi_logloss: 0.121249\n",
      "Early stopping, best iteration is:\n",
      "[160]\tfit's multi_logloss: 0.00335769\tval's multi_logloss: 0.117226\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.138861\tval's multi_logloss: 0.140161\n",
      "[100]\tfit's multi_logloss: 0.0253423\tval's multi_logloss: 0.0554612\n",
      "[150]\tfit's multi_logloss: 0.0059239\tval's multi_logloss: 0.0446788\n",
      "[200]\tfit's multi_logloss: 0.00165123\tval's multi_logloss: 0.0426712\n",
      "Early stopping, best iteration is:\n",
      "[186]\tfit's multi_logloss: 0.00232408\tval's multi_logloss: 0.0421209\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.127218\tval's multi_logloss: 0.193191\n",
      "[100]\tfit's multi_logloss: 0.0224981\tval's multi_logloss: 0.0998974\n",
      "[150]\tfit's multi_logloss: 0.00491895\tval's multi_logloss: 0.0901253\n",
      "Early stopping, best iteration is:\n",
      "[133]\tfit's multi_logloss: 0.00810823\tval's multi_logloss: 0.0898027\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.126381\tval's multi_logloss: 0.199622\n",
      "[100]\tfit's multi_logloss: 0.0228203\tval's multi_logloss: 0.119289\n",
      "[150]\tfit's multi_logloss: 0.00489473\tval's multi_logloss: 0.110922\n",
      "Early stopping, best iteration is:\n",
      "[144]\tfit's multi_logloss: 0.005839\tval's multi_logloss: 0.110312\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.126997\tval's multi_logloss: 0.1878\n",
      "[100]\tfit's multi_logloss: 0.0218631\tval's multi_logloss: 0.10379\n",
      "[150]\tfit's multi_logloss: 0.00488697\tval's multi_logloss: 0.0902812\n",
      "[200]\tfit's multi_logloss: 0.00130167\tval's multi_logloss: 0.0936825\n",
      "Early stopping, best iteration is:\n",
      "[151]\tfit's multi_logloss: 0.00475299\tval's multi_logloss: 0.0900983\n",
      "- Train logloss: 0.001 (±0.000)\n",
      "- Valid logloss: 0.094 (±0.027)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "params = {\n",
    "    'application': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_classes': y_train_gal.nunique(),\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_threads': 8,\n",
    "    'num_leaves': 2 ** 3,\n",
    "    'min_data_per_group': 300,\n",
    "    'max_cat_threshold': 32,\n",
    "    'max_cat_to_onehot': 6,\n",
    "    'cat_smooth': 30,\n",
    "    'cat_l2': 10,\n",
    "    'max_bin': 255,\n",
    "    'min_data_in_bin': 20,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'learning_rate': 0.08,\n",
    "    'feature_fraction': 1,\n",
    "    'feature_fraction_seed': 42,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 0,\n",
    "    'bagging_seed': 42,\n",
    "    'lambda_l1': 0.01,\n",
    "    'lambda_l2': 0.001,\n",
    "    'verbosity': 2,\n",
    "}\n",
    "        \n",
    "\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "feature_importances = pd.DataFrame(index=X_train_gal.columns)\n",
    "gal_fit_scores = np.zeros(cv.n_splits)\n",
    "gal_val_scores = np.zeros(cv.n_splits)\n",
    "submission.loc[X_test_gal.index, y_train_gal.unique()] = 0.0\n",
    "\n",
    "for i, (fit_idx, val_idx) in enumerate(cv.split(X_train_gal, y_train_gal)):\n",
    "    \n",
    "    X_fit = X_train_gal.iloc[fit_idx]\n",
    "    y_fit = y_train_gal.iloc[fit_idx].map(class_to_int)\n",
    "    w_fit = y_train_gal.iloc[fit_idx].map(class_weights)\n",
    "    X_val = X_train_gal.iloc[val_idx]\n",
    "    y_val = y_train_gal.iloc[val_idx].map(class_to_int)\n",
    "    w_val = y_train_gal.iloc[val_idx].map(class_weights)\n",
    "    \n",
    "    # Train the model\n",
    "    fit_set = lgbm.Dataset(X_fit, y_fit, weight=w_fit)\n",
    "    val_set = lgbm.Dataset(X_val, y_val, reference=fit_set, weight=w_val)\n",
    "\n",
    "    evals_result = {}\n",
    "    model = lgbm.train(\n",
    "        params=params,\n",
    "        train_set=fit_set,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=(fit_set, val_set),\n",
    "        valid_names=('fit', 'val'),\n",
    "        verbose_eval=50,\n",
    "        early_stopping_rounds=50,\n",
    "        evals_result=evals_result\n",
    "    )\n",
    "    \n",
    "    # Store the feature importances\n",
    "    feature_importances[f'gain_{i}'] = model.feature_importance('gain')\n",
    "    feature_importances[f'split_{i}'] = model.feature_importance('split')\n",
    "    \n",
    "    # Store the predictions\n",
    "    y_pred = pd.DataFrame(model.predict(X_test_gal), index=X_test_gal.index)\n",
    "    y_pred.columns = y_pred.columns.map(int_to_class)\n",
    "    submission.loc[y_pred.index, y_pred.columns] += y_pred / cv.n_splits\n",
    "    \n",
    "    # Store the scores\n",
    "    gal_fit_scores[i] = evals_result['fit']['multi_logloss'][-1]\n",
    "    gal_val_scores[i] = evals_result['val']['multi_logloss'][-1]\n",
    "\n",
    "print(f'- Train logloss: {gal_fit_scores.mean():.3f} (±{gal_fit_scores.std():.3f})')\n",
    "print(f'- Valid logloss: {gal_val_scores.mean():.3f} (±{gal_val_scores.std():.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train logloss: 0.002 (±0.001)\n",
    "- Valid logloss: 0.091 (±0.028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gain_0</th>\n",
       "      <th>split_0</th>\n",
       "      <th>gain_1</th>\n",
       "      <th>split_1</th>\n",
       "      <th>gain_2</th>\n",
       "      <th>split_2</th>\n",
       "      <th>gain_3</th>\n",
       "      <th>split_3</th>\n",
       "      <th>gain_4</th>\n",
       "      <th>split_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flux_skew_2</th>\n",
       "      <td>6268.342500</td>\n",
       "      <td>274</td>\n",
       "      <td>6185.212210</td>\n",
       "      <td>258</td>\n",
       "      <td>6429.423737</td>\n",
       "      <td>209</td>\n",
       "      <td>6223.756176</td>\n",
       "      <td>238</td>\n",
       "      <td>6167.066547</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_min_2</th>\n",
       "      <td>4398.438483</td>\n",
       "      <td>77</td>\n",
       "      <td>3199.334359</td>\n",
       "      <td>95</td>\n",
       "      <td>3744.417710</td>\n",
       "      <td>91</td>\n",
       "      <td>4597.056659</td>\n",
       "      <td>89</td>\n",
       "      <td>4469.617465</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_max_1</th>\n",
       "      <td>2673.007779</td>\n",
       "      <td>70</td>\n",
       "      <td>2307.707500</td>\n",
       "      <td>81</td>\n",
       "      <td>2585.771134</td>\n",
       "      <td>58</td>\n",
       "      <td>2324.724651</td>\n",
       "      <td>64</td>\n",
       "      <td>2345.841771</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_err_mean_1</th>\n",
       "      <td>1813.655786</td>\n",
       "      <td>55</td>\n",
       "      <td>2452.766638</td>\n",
       "      <td>33</td>\n",
       "      <td>2260.552261</td>\n",
       "      <td>40</td>\n",
       "      <td>1094.681437</td>\n",
       "      <td>39</td>\n",
       "      <td>1411.550384</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_skew_1</th>\n",
       "      <td>1103.994437</td>\n",
       "      <td>222</td>\n",
       "      <td>868.260065</td>\n",
       "      <td>231</td>\n",
       "      <td>890.892121</td>\n",
       "      <td>171</td>\n",
       "      <td>885.035262</td>\n",
       "      <td>165</td>\n",
       "      <td>870.010742</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      gain_0  split_0       gain_1  split_1       gain_2  \\\n",
       "flux_skew_2      6268.342500      274  6185.212210      258  6429.423737   \n",
       "flux_min_2       4398.438483       77  3199.334359       95  3744.417710   \n",
       "flux_max_1       2673.007779       70  2307.707500       81  2585.771134   \n",
       "flux_err_mean_1  1813.655786       55  2452.766638       33  2260.552261   \n",
       "flux_skew_1      1103.994437      222   868.260065      231   890.892121   \n",
       "\n",
       "                 split_2       gain_3  split_3       gain_4  split_4  \n",
       "flux_skew_2          209  6223.756176      238  6167.066547      221  \n",
       "flux_min_2            91  4597.056659       89  4469.617465      102  \n",
       "flux_max_1            58  2324.724651       64  2345.841771       85  \n",
       "flux_err_mean_1       40  1094.681437       39  1411.550384       34  \n",
       "flux_skew_1          171   885.035262      165   870.010742      207  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.sort_values('gain_0', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extragalactic objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the extragalactic objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ex = X_train[X_train['hostgal_photoz'] > 0]\n",
    "y_train_ex = y_train[X_train['hostgal_photoz'] > 0]\n",
    "X_test_ex = X_test[X_test['hostgal_photoz'] > 0]\n",
    "\n",
    "class_to_int = {c: i for i, c in enumerate(y_train_ex.unique())}\n",
    "int_to_class = {i: c for c, i in class_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.643759\tval's multi_logloss: 1.0054\n",
      "[100]\tfit's multi_logloss: 0.37406\tval's multi_logloss: 0.937066\n",
      "[150]\tfit's multi_logloss: 0.243032\tval's multi_logloss: 0.928959\n",
      "Early stopping, best iteration is:\n",
      "[141]\tfit's multi_logloss: 0.261112\tval's multi_logloss: 0.928419\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.64593\tval's multi_logloss: 0.965183\n",
      "[100]\tfit's multi_logloss: 0.376948\tval's multi_logloss: 0.89567\n",
      "[150]\tfit's multi_logloss: 0.245991\tval's multi_logloss: 0.893025\n",
      "Early stopping, best iteration is:\n",
      "[136]\tfit's multi_logloss: 0.274855\tval's multi_logloss: 0.889508\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.649332\tval's multi_logloss: 0.96035\n",
      "[100]\tfit's multi_logloss: 0.381577\tval's multi_logloss: 0.886196\n",
      "[150]\tfit's multi_logloss: 0.250663\tval's multi_logloss: 0.866362\n",
      "[200]\tfit's multi_logloss: 0.175758\tval's multi_logloss: 0.869765\n",
      "Early stopping, best iteration is:\n",
      "[184]\tfit's multi_logloss: 0.195462\tval's multi_logloss: 0.86493\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.642972\tval's multi_logloss: 0.984666\n",
      "[100]\tfit's multi_logloss: 0.372907\tval's multi_logloss: 0.921833\n",
      "[150]\tfit's multi_logloss: 0.242311\tval's multi_logloss: 0.918274\n",
      "Early stopping, best iteration is:\n",
      "[142]\tfit's multi_logloss: 0.257963\tval's multi_logloss: 0.915953\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.639572\tval's multi_logloss: 1.02933\n",
      "[100]\tfit's multi_logloss: 0.371262\tval's multi_logloss: 0.970389\n",
      "[150]\tfit's multi_logloss: 0.242485\tval's multi_logloss: 0.964162\n",
      "Early stopping, best iteration is:\n",
      "[136]\tfit's multi_logloss: 0.270633\tval's multi_logloss: 0.960995\n",
      "- Train logloss: 0.175 (±0.017)\n",
      "- Valid logloss: 0.921 (±0.035)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "params = {\n",
    "    'application': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_classes': y_train_ex.nunique(),\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_threads': 8,\n",
    "    'num_leaves': 2 ** 4,\n",
    "    'min_data_per_group': 300,\n",
    "    'max_cat_threshold': 32,\n",
    "    'max_cat_to_onehot': 6,\n",
    "    'cat_smooth': 30,\n",
    "    'cat_l2': 10,\n",
    "    'max_bin': 255,\n",
    "    'min_data_in_bin': 20,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.7,\n",
    "    'feature_fraction_seed': 42,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 0,\n",
    "    'bagging_seed': 42,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 2,\n",
    "    'verbosity': 2,\n",
    "}\n",
    "        \n",
    "\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "feature_importances = pd.DataFrame(index=X_train_ex.columns)\n",
    "ex_fit_scores = np.zeros(cv.n_splits)\n",
    "ex_val_scores = np.zeros(cv.n_splits)\n",
    "submission.loc[X_test_ex.index, y_train_ex.unique()] = 0.0\n",
    "\n",
    "for i, (fit_idx, val_idx) in enumerate(cv.split(X_train_ex, y_train_ex)):\n",
    "    \n",
    "    X_fit = X_train_ex.iloc[fit_idx]\n",
    "    y_fit = y_train_ex.iloc[fit_idx].map(class_to_int)\n",
    "    w_fit = y_train_ex.iloc[fit_idx].map(class_weights)\n",
    "    X_val = X_train_ex.iloc[val_idx]\n",
    "    y_val = y_train_ex.iloc[val_idx].map(class_to_int)\n",
    "    w_val = y_train_ex.iloc[val_idx].map(class_weights)\n",
    "    \n",
    "    # Train the model\n",
    "    fit_set = lgbm.Dataset(X_fit, y_fit, weight=w_fit)\n",
    "    val_set = lgbm.Dataset(X_val, y_val, reference=fit_set, weight=w_val)\n",
    "    \n",
    "    evals_result = {}\n",
    "    model = lgbm.train(\n",
    "        params=params,\n",
    "        train_set=fit_set,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=(fit_set, val_set),\n",
    "        valid_names=('fit', 'val'),\n",
    "        verbose_eval=50,\n",
    "        early_stopping_rounds=50,\n",
    "        evals_result=evals_result\n",
    "    )\n",
    "    \n",
    "    # Store the feature importances\n",
    "    feature_importances[f'gain_{i}'] = model.feature_importance('gain')\n",
    "    feature_importances[f'split_{i}'] = model.feature_importance('split')\n",
    "    \n",
    "    # Store the predictions\n",
    "    y_pred = pd.DataFrame(model.predict(X_test_ex), index=X_test_ex.index)\n",
    "    y_pred.columns = y_pred.columns.map(int_to_class)\n",
    "    submission.loc[y_pred.index, y_pred.columns] += y_pred / cv.n_splits\n",
    "    \n",
    "    # Store the scores\n",
    "    ex_fit_scores[i] = evals_result['fit']['multi_logloss'][-1]\n",
    "    ex_val_scores[i] = evals_result['val']['multi_logloss'][-1]\n",
    "\n",
    "print(f'- Train logloss: {ex_fit_scores.mean():.3f} (±{ex_fit_scores.std():.3f})')\n",
    "print(f'- Valid logloss: {ex_val_scores.mean():.3f} (±{ex_val_scores.std():.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train logloss: 0.163 (±0.013)\n",
    "- Valid logloss: 0.870 (±0.030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gain_0</th>\n",
       "      <th>split_0</th>\n",
       "      <th>gain_1</th>\n",
       "      <th>split_1</th>\n",
       "      <th>gain_2</th>\n",
       "      <th>split_2</th>\n",
       "      <th>gain_3</th>\n",
       "      <th>split_3</th>\n",
       "      <th>gain_4</th>\n",
       "      <th>split_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <td>5032.842919</td>\n",
       "      <td>557</td>\n",
       "      <td>5096.438541</td>\n",
       "      <td>607</td>\n",
       "      <td>3807.106237</td>\n",
       "      <td>662</td>\n",
       "      <td>3865.951820</td>\n",
       "      <td>484</td>\n",
       "      <td>5714.119225</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_mean_0</th>\n",
       "      <td>4904.933324</td>\n",
       "      <td>399</td>\n",
       "      <td>4818.442032</td>\n",
       "      <td>339</td>\n",
       "      <td>5150.897088</td>\n",
       "      <td>416</td>\n",
       "      <td>4569.698603</td>\n",
       "      <td>317</td>\n",
       "      <td>4515.560972</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distmod</th>\n",
       "      <td>4112.976403</td>\n",
       "      <td>443</td>\n",
       "      <td>3997.782390</td>\n",
       "      <td>404</td>\n",
       "      <td>5305.585292</td>\n",
       "      <td>483</td>\n",
       "      <td>5424.734604</td>\n",
       "      <td>495</td>\n",
       "      <td>3682.956371</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_min_1</th>\n",
       "      <td>4035.697156</td>\n",
       "      <td>251</td>\n",
       "      <td>3685.435178</td>\n",
       "      <td>212</td>\n",
       "      <td>3450.278714</td>\n",
       "      <td>331</td>\n",
       "      <td>3659.994542</td>\n",
       "      <td>258</td>\n",
       "      <td>3727.274163</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_max_0</th>\n",
       "      <td>2649.276457</td>\n",
       "      <td>235</td>\n",
       "      <td>2155.395661</td>\n",
       "      <td>222</td>\n",
       "      <td>2224.260391</td>\n",
       "      <td>265</td>\n",
       "      <td>2437.389510</td>\n",
       "      <td>215</td>\n",
       "      <td>2739.504185</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gain_0  split_0       gain_1  split_1       gain_2  \\\n",
       "hostgal_photoz  5032.842919      557  5096.438541      607  3807.106237   \n",
       "flux_mean_0     4904.933324      399  4818.442032      339  5150.897088   \n",
       "distmod         4112.976403      443  3997.782390      404  5305.585292   \n",
       "flux_min_1      4035.697156      251  3685.435178      212  3450.278714   \n",
       "flux_max_0      2649.276457      235  2155.395661      222  2224.260391   \n",
       "\n",
       "                split_2       gain_3  split_3       gain_4  split_4  \n",
       "hostgal_photoz      662  3865.951820      484  5714.119225      610  \n",
       "flux_mean_0         416  4569.698603      317  4515.560972      363  \n",
       "distmod             483  5424.734604      495  3682.956371      433  \n",
       "flux_min_1          331  3659.994542      258  3727.274163      235  \n",
       "flux_max_0          265  2437.389510      215  2739.504185      240  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.sort_values('gain_0', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty detection\n",
    "\n",
    "http://scikit-learn.org/stable/modules/outlier_detection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['class_99'] = 1 - submission[submission.columns.drop('class_99')].max(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415565</td>\n",
       "      <td>0.083925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.471693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.047189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059256</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045229</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>0.855370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.606019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029760</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018507</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023316</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.911846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>0.763314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092174</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042884</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.830709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>0.549133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149135</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.793711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.029262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class_15  class_16  class_42  class_52  class_53  class_6  \\\n",
       "object_id                                                              \n",
       "13         0.001499       0.0  0.415565  0.083925       0.0      0.0   \n",
       "14         0.002266       0.0  0.059256  0.018871       0.0      0.0   \n",
       "17         0.001606       0.0  0.029760  0.005006       0.0      0.0   \n",
       "23         0.001093       0.0  0.092174  0.005154       0.0      0.0   \n",
       "34         0.005132       0.0  0.149135  0.030653       0.0      0.0   \n",
       "\n",
       "           class_62  class_64  class_65  class_67  class_88  class_90  \\\n",
       "object_id                                                               \n",
       "13         0.022008  0.000227       0.0  0.003480  0.000508  0.471693   \n",
       "14         0.045229  0.000887       0.0  0.005896  0.008468  0.855370   \n",
       "17         0.018507  0.000812       0.0  0.023316  0.002987  0.911846   \n",
       "23         0.018885  0.001030       0.0  0.042884  0.001620  0.830709   \n",
       "34         0.013828  0.000539       0.0  0.005821  0.000302  0.793711   \n",
       "\n",
       "           class_92  class_95  class_99  \n",
       "object_id                                \n",
       "13              0.0  0.001096  0.047189  \n",
       "14              0.0  0.003757  0.606019  \n",
       "17              0.0  0.006159  0.763314  \n",
       "23              0.0  0.006450  0.549133  \n",
       "34              0.0  0.000879  0.029262  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert submission[X_test['hostgal_photoz'] == 0][y_train_ex.unique().categories].sum().sum() == 0\n",
    "assert submission[X_test['hostgal_photoz'] > 0][y_train_gal.unique().categories].sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the submission. We align with the sample submission just to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'{gal_val_scores.mean():.3f}_{ex_val_scores.mean():.3f}_{out_val_scores.mean():.3f}'\n",
    "\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv').set_index('object_id')\n",
    "\n",
    "submission.loc[sample_sub.index, sample_sub.columns].to_csv(f'submissions/{name}.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2026580625061984"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.log_loss(y_fit, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to DataFrame, shape must be (3102380, 9): given (3102380, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f479a1c04331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mweighted_log_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-f479a1c04331>\u001b[0m in \u001b[0;36mweighted_log_loss\u001b[0;34m(y_true, y_pred, class_weights, eps)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Normalize row-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Limit 0s and 1s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;31m# this makes sure that we are aligned like the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Another DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[0;34m(left, right, axis)\u001b[0m\n\u001b[1;32m   1438\u001b[0m                                  \u001b[0;34m\"must be {req_shape}: given {given_shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m                                  .format(req_shape=left.shape,\n\u001b[0;32m-> 1440\u001b[0;31m                                          given_shape=right.shape))\n\u001b[0m\u001b[1;32m   1441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m             right = left._constructor(right, index=left.index,\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to coerce to DataFrame, shape must be (3102380, 9): given (3102380, 1)"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def weighted_log_loss(y_true, y_pred, class_weights, eps=10e-15):\n",
    "    y_true = preprocessing.LabelBinarizer().fit_transform(y_true)\n",
    "    \n",
    "    # Normalize row-wise\n",
    "    y_pred /= y_pred.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Limit 0s and 1s\n",
    "    y_pred = np.clip(y_pred, eps, 1-eps)\n",
    "    \n",
    "    return -(y_true * np.log(y_pred)).sum(axis=1).mean()\n",
    "    \n",
    "    \n",
    "class_weights = np.array([1] * 14)\n",
    "weighted_log_loss(y_fit, y_pred, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
