{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You only have to run the following cell once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-920c5b06ca78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     (\n\u001b[1;32m     14\u001b[0m         \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/training_set.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test_set.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     ),\n\u001b[1;32m     17\u001b[0m     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m     \"\"\"\n\u001b[1;32m    813\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtypes = {\n",
    "    'object_id': np.uint32,\n",
    "    'mjd': np.float32,\n",
    "    'passband': np.uint8,\n",
    "    'flux': np.float32,\n",
    "    'flux_err': np.float32,\n",
    "    'detected': bool\n",
    "}\n",
    "lcs = pd.concat(\n",
    "    (\n",
    "        pd.read_csv('data/training_set.csv', dtype=dtypes),\n",
    "        pd.read_csv('data/test_set.csv', dtype=dtypes)\n",
    "    ),\n",
    "    sort=False,\n",
    "    ignore_index=True\n",
    ")\n",
    "lcs.to_hdf('data/data.h5', 'light_curves')\n",
    "\n",
    "dtypes = {\n",
    "    'object_id': np.uint32\n",
    "}\n",
    "df = pd.concat(\n",
    "    (\n",
    "        pd.read_csv('data/training_set_metadata.csv', dtype=dtypes),\n",
    "        pd.read_csv('data/test_set_metadata.csv', dtype=dtypes)\n",
    "    ),\n",
    "    sort=False,\n",
    "    ignore_index=True\n",
    ")\n",
    "df['is_train'] = df['target'].notnull()\n",
    "df.to_hdf('data/data.h5', 'meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the HDF5 files (it weights much less than the initial files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "lcs = pd.read_hdf('data/data.h5', 'light_curves')\n",
    "df = pd.read_hdf('data/data.h5', 'meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mjd_to_unix(mjd):\n",
    "    return (mjd - 40587) * 86400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object/passband features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "stats = pd.read_csv('data/features/flux_stats.csv')\\\n",
    "          .pivot(index='object_id', columns='passband')\\\n",
    "          .astype(np.float32)\n",
    "\n",
    "# Collapse the column names\n",
    "names = stats.columns.get_level_values(0)\n",
    "passbands = stats.columns.get_level_values(1).astype(str)\n",
    "stats.columns = ['_'.join(pair) for pair in zip(names, passbands)]\n",
    "\n",
    "stats['flux_diff_min_0'].replace(np.inf, stats['flux_diff_min_0'][stats['flux_diff_min_0'] != np.inf].max(), inplace=True)\n",
    "\n",
    "df = df.join(stats, on='object_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2 = pd.read_csv('data/features/flux_stats2.csv').set_index('object_id')\n",
    "df = df.join(stats2, on='object_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute ratios because why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "for (a, b) in itertools.combinations(range(6), 2):\n",
    "    for stat in ('bfr', 'mean', 'min', 'max', 'ptp', 'skew', 'kurtosis'):\n",
    "        df[f'flux_{stat}_{a}_{b}'] = df[f'flux_{stat}_{a}'] / (df[f'flux_{stat}_{b}'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>decl</th>\n",
       "      <th>gal_l</th>\n",
       "      <th>gal_b</th>\n",
       "      <th>ddf</th>\n",
       "      <th>hostgal_specz</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>distmod</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_ptp_3_5</th>\n",
       "      <th>flux_skew_3_5</th>\n",
       "      <th>flux_kurtosis_3_5</th>\n",
       "      <th>flux_bfr_4_5</th>\n",
       "      <th>flux_mean_4_5</th>\n",
       "      <th>flux_min_4_5</th>\n",
       "      <th>flux_max_4_5</th>\n",
       "      <th>flux_ptp_4_5</th>\n",
       "      <th>flux_skew_4_5</th>\n",
       "      <th>flux_kurtosis_4_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>615</td>\n",
       "      <td>349.046051</td>\n",
       "      <td>-61.943836</td>\n",
       "      <td>320.796530</td>\n",
       "      <td>-51.753706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.217429</td>\n",
       "      <td>0.254461</td>\n",
       "      <td>2.553047</td>\n",
       "      <td>0.940293</td>\n",
       "      <td>1.204624</td>\n",
       "      <td>1.000876</td>\n",
       "      <td>1.007293</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>0.173701</td>\n",
       "      <td>2.714094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>713</td>\n",
       "      <td>53.085938</td>\n",
       "      <td>-27.784405</td>\n",
       "      <td>223.525509</td>\n",
       "      <td>-54.460748</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8181</td>\n",
       "      <td>1.6267</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>45.4063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>-0.134179</td>\n",
       "      <td>-6.874031</td>\n",
       "      <td>0.031504</td>\n",
       "      <td>1.133581</td>\n",
       "      <td>0.930032</td>\n",
       "      <td>0.623169</td>\n",
       "      <td>0.737599</td>\n",
       "      <td>-0.051475</td>\n",
       "      <td>-7.132717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>33.574219</td>\n",
       "      <td>-6.579593</td>\n",
       "      <td>170.455585</td>\n",
       "      <td>-61.548219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>40.2561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578153</td>\n",
       "      <td>0.982566</td>\n",
       "      <td>1.537941</td>\n",
       "      <td>2.819986</td>\n",
       "      <td>0.777834</td>\n",
       "      <td>0.321386</td>\n",
       "      <td>0.851996</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.936143</td>\n",
       "      <td>1.305303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>745</td>\n",
       "      <td>0.189873</td>\n",
       "      <td>-45.586655</td>\n",
       "      <td>328.254458</td>\n",
       "      <td>-68.969298</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>1.1523</td>\n",
       "      <td>40.7951</td>\n",
       "      <td>...</td>\n",
       "      <td>1.362864</td>\n",
       "      <td>0.893881</td>\n",
       "      <td>1.243282</td>\n",
       "      <td>0.960026</td>\n",
       "      <td>1.118192</td>\n",
       "      <td>1.675188</td>\n",
       "      <td>1.288533</td>\n",
       "      <td>1.303509</td>\n",
       "      <td>0.828314</td>\n",
       "      <td>1.041245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1124</td>\n",
       "      <td>352.711273</td>\n",
       "      <td>-63.823658</td>\n",
       "      <td>316.922299</td>\n",
       "      <td>-51.059403</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>40.4166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.178490</td>\n",
       "      <td>0.769534</td>\n",
       "      <td>0.908654</td>\n",
       "      <td>8.674057</td>\n",
       "      <td>1.254454</td>\n",
       "      <td>1.677773</td>\n",
       "      <td>1.303589</td>\n",
       "      <td>1.323305</td>\n",
       "      <td>0.833776</td>\n",
       "      <td>1.056873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id          ra       decl       gal_l      gal_b  ddf  \\\n",
       "0        615  349.046051 -61.943836  320.796530 -51.753706    1   \n",
       "1        713   53.085938 -27.784405  223.525509 -54.460748    1   \n",
       "2        730   33.574219  -6.579593  170.455585 -61.548219    1   \n",
       "3        745    0.189873 -45.586655  328.254458 -68.969298    1   \n",
       "4       1124  352.711273 -63.823658  316.922299 -51.059403    1   \n",
       "\n",
       "   hostgal_specz  hostgal_photoz  hostgal_photoz_err  distmod  \\\n",
       "0         0.0000          0.0000              0.0000      NaN   \n",
       "1         1.8181          1.6267              0.2552  45.4063   \n",
       "2         0.2320          0.2262              0.0157  40.2561   \n",
       "3         0.3037          0.2813              1.1523  40.7951   \n",
       "4         0.1934          0.2415              0.0176  40.4166   \n",
       "\n",
       "         ...          flux_ptp_3_5  flux_skew_3_5  flux_kurtosis_3_5  \\\n",
       "0        ...              1.217429       0.254461           2.553047   \n",
       "1        ...              0.791304      -0.134179          -6.874031   \n",
       "2        ...              0.578153       0.982566           1.537941   \n",
       "3        ...              1.362864       0.893881           1.243282   \n",
       "4        ...              1.178490       0.769534           0.908654   \n",
       "\n",
       "   flux_bfr_4_5  flux_mean_4_5  flux_min_4_5  flux_max_4_5  flux_ptp_4_5  \\\n",
       "0      0.940293       1.204624      1.000876      1.007293      1.002662   \n",
       "1      0.031504       1.133581      0.930032      0.623169      0.737599   \n",
       "2      2.819986       0.777834      0.321386      0.851996      0.696552   \n",
       "3      0.960026       1.118192      1.675188      1.288533      1.303509   \n",
       "4      8.674057       1.254454      1.677773      1.303589      1.323305   \n",
       "\n",
       "   flux_skew_4_5  flux_kurtosis_4_5  \n",
       "0       0.173701           2.714094  \n",
       "1      -0.051475          -7.132717  \n",
       "2       0.936143           1.305303  \n",
       "3       0.828314           1.041245  \n",
       "4       0.833776           1.056873  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['is_train', 'target', 'hostgal_specz']\n",
    "\n",
    "train = df[df['is_train']].set_index('object_id')\n",
    "test = df[~df['is_train']].set_index('object_id')\n",
    "\n",
    "X_train = train.drop(columns=to_drop)\n",
    "y_train = train['target'].apply(lambda x: f'class_{int(x)}').astype('category')\n",
    "X_test = test.drop(columns=to_drop)\n",
    "submission = pd.DataFrame(0.0, index=test.index, columns=y_train.cat.categories)\n",
    "submission['class_99'] = 0.0\n",
    "\n",
    "class_weights = {c: 1 for c in y_train.cat.categories}\n",
    "class_weights['class_64'] = 2\n",
    "class_weights['class_15'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_train.columns) == len(X_test.columns)\n",
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_test) == 3492890\n",
    "assert len(submission) == 3492890"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galactic objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the galactic objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gal = X_train[X_train['hostgal_photoz'] == 0]\n",
    "y_train_gal = y_train[X_train['hostgal_photoz'] == 0]\n",
    "X_test_gal = X_test[X_test['hostgal_photoz'] == 0]\n",
    "\n",
    "class_to_int = {c: i for i, c in enumerate(y_train_gal.unique())}\n",
    "int_to_class = {i: c for c, i in class_to_int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.128621\tval's multi_logloss: 0.200793\n",
      "[100]\tfit's multi_logloss: 0.0209878\tval's multi_logloss: 0.0940356\n",
      "[150]\tfit's multi_logloss: 0.00421758\tval's multi_logloss: 0.0783682\n",
      "[200]\tfit's multi_logloss: 0.000938744\tval's multi_logloss: 0.0772804\n",
      "Early stopping, best iteration is:\n",
      "[198]\tfit's multi_logloss: 0.000998732\tval's multi_logloss: 0.0772504\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.13312\tval's multi_logloss: 0.135975\n",
      "[100]\tfit's multi_logloss: 0.0232558\tval's multi_logloss: 0.0486849\n",
      "[150]\tfit's multi_logloss: 0.00516147\tval's multi_logloss: 0.0361724\n",
      "[200]\tfit's multi_logloss: 0.00119667\tval's multi_logloss: 0.0326759\n",
      "[250]\tfit's multi_logloss: 0.000292402\tval's multi_logloss: 0.0281451\n",
      "[300]\tfit's multi_logloss: 7.41583e-05\tval's multi_logloss: 0.028934\n",
      "Early stopping, best iteration is:\n",
      "[256]\tfit's multi_logloss: 0.000248029\tval's multi_logloss: 0.0274817\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.128744\tval's multi_logloss: 0.197045\n",
      "[100]\tfit's multi_logloss: 0.0216202\tval's multi_logloss: 0.0966007\n",
      "[150]\tfit's multi_logloss: 0.00460217\tval's multi_logloss: 0.0806373\n",
      "[200]\tfit's multi_logloss: 0.00103144\tval's multi_logloss: 0.0791362\n",
      "Early stopping, best iteration is:\n",
      "[181]\tfit's multi_logloss: 0.00177453\tval's multi_logloss: 0.0775532\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.12957\tval's multi_logloss: 0.185481\n",
      "[100]\tfit's multi_logloss: 0.0211988\tval's multi_logloss: 0.11126\n",
      "[150]\tfit's multi_logloss: 0.00420886\tval's multi_logloss: 0.107954\n",
      "Early stopping, best iteration is:\n",
      "[125]\tfit's multi_logloss: 0.00925777\tval's multi_logloss: 0.105504\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.13122\tval's multi_logloss: 0.167741\n",
      "[100]\tfit's multi_logloss: 0.0223709\tval's multi_logloss: 0.0698664\n",
      "[150]\tfit's multi_logloss: 0.00455215\tval's multi_logloss: 0.0559572\n",
      "[200]\tfit's multi_logloss: 0.00127525\tval's multi_logloss: 0.0550764\n",
      "[250]\tfit's multi_logloss: 0.000439025\tval's multi_logloss: 0.0542932\n",
      "Early stopping, best iteration is:\n",
      "[223]\tfit's multi_logloss: 0.000695573\tval's multi_logloss: 0.0510046\n",
      "- Train logloss: 0.001 (±0.001)\n",
      "- Valid logloss: 0.072 (±0.028)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "params = {\n",
    "    'application': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_classes': y_train_gal.nunique(),\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_threads': 8,\n",
    "    'num_leaves': 2 ** 3,\n",
    "    'min_data_per_group': 300,\n",
    "    'max_cat_threshold': 32,\n",
    "    'max_cat_to_onehot': 6,\n",
    "    'cat_smooth': 30,\n",
    "    'cat_l2': 10,\n",
    "    'max_bin': 255,\n",
    "    'min_data_in_bin': 20,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'learning_rate': 0.08,\n",
    "    'feature_fraction': 0.7,\n",
    "    'feature_fraction_seed': 42,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 0,\n",
    "    'bagging_seed': 42,\n",
    "    'lambda_l1': 0,\n",
    "    'lambda_l2': 0,\n",
    "    'verbosity': 2,\n",
    "}\n",
    "        \n",
    "\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "feature_importances = pd.DataFrame(index=X_train_gal.columns)\n",
    "gal_fit_scores = np.zeros(cv.n_splits)\n",
    "gal_val_scores = np.zeros(cv.n_splits)\n",
    "submission.loc[X_test_gal.index, y_train_gal.unique()] = 0.0\n",
    "\n",
    "for i, (fit_idx, val_idx) in enumerate(cv.split(X_train_gal, y_train_gal)):\n",
    "    \n",
    "    X_fit = X_train_gal.iloc[fit_idx]\n",
    "    y_fit = y_train_gal.iloc[fit_idx].map(class_to_int)\n",
    "    w_fit = y_train_gal.iloc[fit_idx].map(class_weights)\n",
    "    X_val = X_train_gal.iloc[val_idx]\n",
    "    y_val = y_train_gal.iloc[val_idx].map(class_to_int)\n",
    "    w_val = y_train_gal.iloc[val_idx].map(class_weights)\n",
    "    \n",
    "    # Train the model\n",
    "    fit_set = lgbm.Dataset(X_fit, y_fit, weight=w_fit)\n",
    "    val_set = lgbm.Dataset(X_val, y_val, reference=fit_set, weight=w_val)\n",
    "\n",
    "    evals_result = {}\n",
    "    model = lgbm.train(\n",
    "        params=params,\n",
    "        train_set=fit_set,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=(fit_set, val_set),\n",
    "        valid_names=('fit', 'val'),\n",
    "        verbose_eval=50,\n",
    "        early_stopping_rounds=50,\n",
    "        evals_result=evals_result\n",
    "    )\n",
    "    \n",
    "    # Store the feature importances\n",
    "    feature_importances[f'gain_{i}'] = model.feature_importance('gain')\n",
    "    feature_importances[f'split_{i}'] = model.feature_importance('split')\n",
    "    \n",
    "    # Store the predictions\n",
    "    y_pred = pd.DataFrame(model.predict(X_test_gal), index=X_test_gal.index)\n",
    "    y_pred.columns = y_pred.columns.map(int_to_class)\n",
    "    submission.loc[y_pred.index, y_pred.columns] += y_pred / cv.n_splits\n",
    "    \n",
    "    # Store the scores\n",
    "    gal_fit_scores[i] = evals_result['fit']['multi_logloss'][-1]\n",
    "    gal_val_scores[i] = evals_result['val']['multi_logloss'][-1]\n",
    "\n",
    "print(f'- Train logloss: {gal_fit_scores.mean():.3f} (±{gal_fit_scores.std():.3f})')\n",
    "print(f'- Valid logloss: {gal_val_scores.mean():.3f} (±{gal_val_scores.std():.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train logloss: 0.001 (±0.001)\n",
    "- Valid logloss: 0.072 (±0.028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gain_0</th>\n",
       "      <th>split_0</th>\n",
       "      <th>gain_1</th>\n",
       "      <th>split_1</th>\n",
       "      <th>gain_2</th>\n",
       "      <th>split_2</th>\n",
       "      <th>gain_3</th>\n",
       "      <th>split_3</th>\n",
       "      <th>gain_4</th>\n",
       "      <th>split_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flux_skew_2</th>\n",
       "      <td>3923.312595</td>\n",
       "      <td>245</td>\n",
       "      <td>3864.632253</td>\n",
       "      <td>263</td>\n",
       "      <td>3936.560117</td>\n",
       "      <td>226</td>\n",
       "      <td>3991.861857</td>\n",
       "      <td>192</td>\n",
       "      <td>3846.072873</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_min_0_2</th>\n",
       "      <td>3275.177206</td>\n",
       "      <td>110</td>\n",
       "      <td>2515.655173</td>\n",
       "      <td>112</td>\n",
       "      <td>3731.891790</td>\n",
       "      <td>99</td>\n",
       "      <td>2308.091591</td>\n",
       "      <td>57</td>\n",
       "      <td>2628.702468</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_max_1</th>\n",
       "      <td>1713.459198</td>\n",
       "      <td>46</td>\n",
       "      <td>1292.323942</td>\n",
       "      <td>55</td>\n",
       "      <td>1463.907245</td>\n",
       "      <td>39</td>\n",
       "      <td>1684.991553</td>\n",
       "      <td>43</td>\n",
       "      <td>1435.815768</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_err_mean_1</th>\n",
       "      <td>1059.900253</td>\n",
       "      <td>126</td>\n",
       "      <td>1226.947777</td>\n",
       "      <td>102</td>\n",
       "      <td>823.756809</td>\n",
       "      <td>107</td>\n",
       "      <td>814.487945</td>\n",
       "      <td>64</td>\n",
       "      <td>1161.369968</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_min_2_5</th>\n",
       "      <td>785.890369</td>\n",
       "      <td>90</td>\n",
       "      <td>598.553954</td>\n",
       "      <td>150</td>\n",
       "      <td>579.932184</td>\n",
       "      <td>122</td>\n",
       "      <td>529.984494</td>\n",
       "      <td>88</td>\n",
       "      <td>144.868597</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      gain_0  split_0       gain_1  split_1       gain_2  \\\n",
       "flux_skew_2      3923.312595      245  3864.632253      263  3936.560117   \n",
       "flux_min_0_2     3275.177206      110  2515.655173      112  3731.891790   \n",
       "flux_max_1       1713.459198       46  1292.323942       55  1463.907245   \n",
       "flux_err_mean_1  1059.900253      126  1226.947777      102   823.756809   \n",
       "flux_min_2_5      785.890369       90   598.553954      150   579.932184   \n",
       "\n",
       "                 split_2       gain_3  split_3       gain_4  split_4  \n",
       "flux_skew_2          226  3991.861857      192  3846.072873      248  \n",
       "flux_min_0_2          99  2308.091591       57  2628.702468       89  \n",
       "flux_max_1            39  1684.991553       43  1435.815768       72  \n",
       "flux_err_mean_1      107   814.487945       64  1161.369968       93  \n",
       "flux_min_2_5         122   529.984494       88   144.868597       99  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.sort_values('gain_0', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extragalactic objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the extragalactic objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ex = X_train[X_train['hostgal_photoz'] > 0]\n",
    "y_train_ex = y_train[X_train['hostgal_photoz'] > 0]\n",
    "X_test_ex = X_test[X_test['hostgal_photoz'] > 0]\n",
    "\n",
    "class_to_int = {c: i for i, c in enumerate(y_train_ex.unique())}\n",
    "int_to_class = {i: c for c, i in class_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.855813\tval's multi_logloss: 1.0364\n",
      "[100]\tfit's multi_logloss: 0.615097\tval's multi_logloss: 0.906576\n",
      "[150]\tfit's multi_logloss: 0.484772\tval's multi_logloss: 0.868299\n",
      "[200]\tfit's multi_logloss: 0.39619\tval's multi_logloss: 0.853095\n",
      "[250]\tfit's multi_logloss: 0.330429\tval's multi_logloss: 0.850368\n",
      "[300]\tfit's multi_logloss: 0.279836\tval's multi_logloss: 0.848187\n",
      "[350]\tfit's multi_logloss: 0.239848\tval's multi_logloss: 0.849843\n",
      "Early stopping, best iteration is:\n",
      "[323]\tfit's multi_logloss: 0.260222\tval's multi_logloss: 0.847664\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.86565\tval's multi_logloss: 0.985339\n",
      "[100]\tfit's multi_logloss: 0.622524\tval's multi_logloss: 0.856409\n",
      "[150]\tfit's multi_logloss: 0.490689\tval's multi_logloss: 0.81911\n",
      "[200]\tfit's multi_logloss: 0.401764\tval's multi_logloss: 0.802765\n",
      "[250]\tfit's multi_logloss: 0.335043\tval's multi_logloss: 0.798324\n",
      "[300]\tfit's multi_logloss: 0.283978\tval's multi_logloss: 0.79587\n",
      "[350]\tfit's multi_logloss: 0.242803\tval's multi_logloss: 0.797147\n",
      "Early stopping, best iteration is:\n",
      "[325]\tfit's multi_logloss: 0.262236\tval's multi_logloss: 0.795748\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.858242\tval's multi_logloss: 1.00534\n",
      "[100]\tfit's multi_logloss: 0.620032\tval's multi_logloss: 0.873985\n",
      "[150]\tfit's multi_logloss: 0.489248\tval's multi_logloss: 0.830081\n",
      "[200]\tfit's multi_logloss: 0.399071\tval's multi_logloss: 0.811206\n",
      "[250]\tfit's multi_logloss: 0.332346\tval's multi_logloss: 0.802837\n",
      "[300]\tfit's multi_logloss: 0.281768\tval's multi_logloss: 0.800861\n",
      "[350]\tfit's multi_logloss: 0.241229\tval's multi_logloss: 0.800799\n",
      "[400]\tfit's multi_logloss: 0.208587\tval's multi_logloss: 0.801934\n",
      "Early stopping, best iteration is:\n",
      "[379]\tfit's multi_logloss: 0.221684\tval's multi_logloss: 0.799245\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.852651\tval's multi_logloss: 1.01205\n",
      "[100]\tfit's multi_logloss: 0.611289\tval's multi_logloss: 0.896862\n",
      "[150]\tfit's multi_logloss: 0.479869\tval's multi_logloss: 0.863793\n",
      "[200]\tfit's multi_logloss: 0.391182\tval's multi_logloss: 0.847738\n",
      "[250]\tfit's multi_logloss: 0.325052\tval's multi_logloss: 0.845771\n",
      "[300]\tfit's multi_logloss: 0.274976\tval's multi_logloss: 0.84537\n",
      "Early stopping, best iteration is:\n",
      "[271]\tfit's multi_logloss: 0.302403\tval's multi_logloss: 0.84448\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tfit's multi_logloss: 0.847826\tval's multi_logloss: 1.05246\n",
      "[100]\tfit's multi_logloss: 0.609057\tval's multi_logloss: 0.938255\n",
      "[150]\tfit's multi_logloss: 0.478118\tval's multi_logloss: 0.903533\n",
      "[200]\tfit's multi_logloss: 0.390044\tval's multi_logloss: 0.894091\n",
      "[250]\tfit's multi_logloss: 0.324385\tval's multi_logloss: 0.88831\n",
      "[300]\tfit's multi_logloss: 0.274509\tval's multi_logloss: 0.887335\n",
      "Early stopping, best iteration is:\n",
      "[291]\tfit's multi_logloss: 0.282784\tval's multi_logloss: 0.886099\n",
      "- Train logloss: 0.228 (±0.022)\n",
      "- Valid logloss: 0.839 (±0.035)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "params = {\n",
    "    'application': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_classes': y_train_ex.nunique(),\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_threads': 8,\n",
    "    'num_leaves': 2 ** 4,\n",
    "    'min_data_per_group': 300,\n",
    "    'max_cat_threshold': 32,\n",
    "    'max_cat_to_onehot': 6,\n",
    "    'cat_smooth': 30,\n",
    "    'cat_l2': 10,\n",
    "    'max_bin': 255,\n",
    "    'min_data_in_bin': 20,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'feature_fraction_seed': 42,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 0,\n",
    "    'bagging_seed': 42,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 2,\n",
    "    'verbosity': 2,\n",
    "}\n",
    "        \n",
    "\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "feature_importances = pd.DataFrame(index=X_train_ex.columns)\n",
    "ex_fit_scores = np.zeros(cv.n_splits)\n",
    "ex_val_scores = np.zeros(cv.n_splits)\n",
    "submission.loc[X_test_ex.index, y_train_ex.unique()] = 0.0\n",
    "\n",
    "for i, (fit_idx, val_idx) in enumerate(cv.split(X_train_ex, y_train_ex)):\n",
    "    \n",
    "    X_fit = X_train_ex.iloc[fit_idx]\n",
    "    y_fit = y_train_ex.iloc[fit_idx].map(class_to_int)\n",
    "    w_fit = y_train_ex.iloc[fit_idx].map(class_weights)\n",
    "    X_val = X_train_ex.iloc[val_idx]\n",
    "    y_val = y_train_ex.iloc[val_idx].map(class_to_int)\n",
    "    w_val = y_train_ex.iloc[val_idx].map(class_weights)\n",
    "    \n",
    "    # Train the model\n",
    "    fit_set = lgbm.Dataset(X_fit.values.astype(np.float32), y_fit, weight=w_fit)\n",
    "    val_set = lgbm.Dataset(X_val.values.astype(np.float32), y_val, reference=fit_set, weight=w_val)\n",
    "    \n",
    "    evals_result = {}\n",
    "    model = lgbm.train(\n",
    "        params=params,\n",
    "        train_set=fit_set,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=(fit_set, val_set),\n",
    "        valid_names=('fit', 'val'),\n",
    "        verbose_eval=50,\n",
    "        early_stopping_rounds=50,\n",
    "        evals_result=evals_result\n",
    "    )\n",
    "    \n",
    "    # Store the feature importances\n",
    "    feature_importances[f'gain_{i}'] = model.feature_importance('gain')\n",
    "    feature_importances[f'split_{i}'] = model.feature_importance('split')\n",
    "    \n",
    "    # Store the predictions\n",
    "    y_pred = pd.DataFrame(model.predict(X_test_ex.values.astype(np.float32)), index=X_test_ex.index)\n",
    "    y_pred.columns = y_pred.columns.map(int_to_class)\n",
    "    submission.loc[y_pred.index, y_pred.columns] += y_pred / cv.n_splits\n",
    "    \n",
    "    # Store the scores\n",
    "    ex_fit_scores[i] = evals_result['fit']['multi_logloss'][-1]\n",
    "    ex_val_scores[i] = evals_result['val']['multi_logloss'][-1]\n",
    "\n",
    "print(f'- Train logloss: {ex_fit_scores.mean():.3f} (±{ex_fit_scores.std():.3f})')\n",
    "print(f'- Valid logloss: {ex_val_scores.mean():.3f} (±{ex_val_scores.std():.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train logloss: 0.228 (±0.022)\n",
    "- Valid logloss: 0.839 (±0.035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gain_0</th>\n",
       "      <th>split_0</th>\n",
       "      <th>gain_1</th>\n",
       "      <th>split_1</th>\n",
       "      <th>gain_2</th>\n",
       "      <th>split_2</th>\n",
       "      <th>gain_3</th>\n",
       "      <th>split_3</th>\n",
       "      <th>gain_4</th>\n",
       "      <th>split_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distmod</th>\n",
       "      <td>5232.722202</td>\n",
       "      <td>553</td>\n",
       "      <td>4395.977741</td>\n",
       "      <td>512</td>\n",
       "      <td>5112.973466</td>\n",
       "      <td>539</td>\n",
       "      <td>6137.207058</td>\n",
       "      <td>508</td>\n",
       "      <td>5003.321872</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <td>4423.982320</td>\n",
       "      <td>556</td>\n",
       "      <td>5319.860550</td>\n",
       "      <td>671</td>\n",
       "      <td>4676.300651</td>\n",
       "      <td>648</td>\n",
       "      <td>3706.277157</td>\n",
       "      <td>467</td>\n",
       "      <td>4649.583332</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_min_1</th>\n",
       "      <td>3432.067098</td>\n",
       "      <td>176</td>\n",
       "      <td>3038.369926</td>\n",
       "      <td>148</td>\n",
       "      <td>2614.418820</td>\n",
       "      <td>169</td>\n",
       "      <td>3070.556864</td>\n",
       "      <td>154</td>\n",
       "      <td>3163.811519</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_max_0_4</th>\n",
       "      <td>2505.937873</td>\n",
       "      <td>93</td>\n",
       "      <td>1695.758131</td>\n",
       "      <td>81</td>\n",
       "      <td>2352.623481</td>\n",
       "      <td>120</td>\n",
       "      <td>2312.764972</td>\n",
       "      <td>92</td>\n",
       "      <td>3119.292677</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux_mean_0_4</th>\n",
       "      <td>2318.959552</td>\n",
       "      <td>86</td>\n",
       "      <td>1465.185663</td>\n",
       "      <td>73</td>\n",
       "      <td>1367.641956</td>\n",
       "      <td>86</td>\n",
       "      <td>1616.380340</td>\n",
       "      <td>59</td>\n",
       "      <td>748.188956</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gain_0  split_0       gain_1  split_1       gain_2  \\\n",
       "distmod         5232.722202      553  4395.977741      512  5112.973466   \n",
       "hostgal_photoz  4423.982320      556  5319.860550      671  4676.300651   \n",
       "flux_min_1      3432.067098      176  3038.369926      148  2614.418820   \n",
       "flux_max_0_4    2505.937873       93  1695.758131       81  2352.623481   \n",
       "flux_mean_0_4   2318.959552       86  1465.185663       73  1367.641956   \n",
       "\n",
       "                split_2       gain_3  split_3       gain_4  split_4  \n",
       "distmod             539  6137.207058      508  5003.321872      461  \n",
       "hostgal_photoz      648  3706.277157      467  4649.583332      587  \n",
       "flux_min_1          169  3070.556864      154  3163.811519      123  \n",
       "flux_max_0_4        120  2312.764972       92  3119.292677       68  \n",
       "flux_mean_0_4        86  1616.380340       59   748.188956       69  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.sort_values('gain_0', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['class_99'] = (1 - submission[submission.columns.drop('class_99')].max(axis='columns')) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538966</td>\n",
       "      <td>0.032829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040014</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.382606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.230517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192385</td>\n",
       "      <td>0.028432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.739839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.130080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084542</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.868628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.065686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134251</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050753</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061123</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.730264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.134868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034112</td>\n",
       "      <td>0.063115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.892646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.053677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class_15  class_16  class_42  class_52  class_53  class_6  \\\n",
       "object_id                                                              \n",
       "13         0.000559       0.0  0.538966  0.032829       0.0      0.0   \n",
       "14         0.010043       0.0  0.192385  0.028432       0.0      0.0   \n",
       "17         0.002264       0.0  0.084542  0.015490       0.0      0.0   \n",
       "23         0.000852       0.0  0.134251  0.010185       0.0      0.0   \n",
       "34         0.001118       0.0  0.034112  0.063115       0.0      0.0   \n",
       "\n",
       "           class_62  class_64  class_65  class_67  class_88  class_90  \\\n",
       "object_id                                                               \n",
       "13         0.040014  0.000053       0.0  0.004167  0.000176  0.382606   \n",
       "14         0.017030  0.001124       0.0  0.003811  0.003508  0.739839   \n",
       "17         0.017709  0.000730       0.0  0.003700  0.001085  0.868628   \n",
       "23         0.050753  0.000431       0.0  0.061123  0.000770  0.730264   \n",
       "34         0.007006  0.000074       0.0  0.001586  0.000083  0.892646   \n",
       "\n",
       "           class_92  class_95  class_99  \n",
       "object_id                                \n",
       "13              0.0  0.000631  0.230517  \n",
       "14              0.0  0.003828  0.130080  \n",
       "17              0.0  0.005852  0.065686  \n",
       "23              0.0  0.011370  0.134868  \n",
       "34              0.0  0.000259  0.053677  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert submission[X_test['hostgal_photoz'] == 0][y_train_ex.unique().categories].sum().sum() == 0\n",
    "assert submission[X_test['hostgal_photoz'] > 0][y_train_gal.unique().categories].sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the submission. We align with the sample submission just to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'{gal_val_scores.mean():.3f}_{gal_val_scores.std():.3f}_{ex_val_scores.mean():.3f}_{ex_val_scores.std():.3f}'\n",
    "\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv').set_index('object_id')\n",
    "\n",
    "submission.loc[sample_sub.index, sample_sub.columns].to_csv(f'submissions/{name}.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2026580625061984"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.log_loss(y_fit, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to DataFrame, shape must be (3102380, 9): given (3102380, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f479a1c04331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mweighted_log_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-f479a1c04331>\u001b[0m in \u001b[0;36mweighted_log_loss\u001b[0;34m(y_true, y_pred, class_weights, eps)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Normalize row-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Limit 0s and 1s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;31m# this makes sure that we are aligned like the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Another DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[0;34m(left, right, axis)\u001b[0m\n\u001b[1;32m   1438\u001b[0m                                  \u001b[0;34m\"must be {req_shape}: given {given_shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m                                  .format(req_shape=left.shape,\n\u001b[0;32m-> 1440\u001b[0;31m                                          given_shape=right.shape))\n\u001b[0m\u001b[1;32m   1441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m             right = left._constructor(right, index=left.index,\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to coerce to DataFrame, shape must be (3102380, 9): given (3102380, 1)"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def weighted_log_loss(y_true, y_pred, class_weights, eps=10e-15):\n",
    "    y_true = preprocessing.LabelBinarizer().fit_transform(y_true)\n",
    "    \n",
    "    # Normalize row-wise\n",
    "    y_pred /= y_pred.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Limit 0s and 1s\n",
    "    y_pred = np.clip(y_pred, eps, 1-eps)\n",
    "    \n",
    "    return -(y_true * np.log(y_pred)).sum(axis=1).mean()\n",
    "    \n",
    "    \n",
    "class_weights = np.array([1] * 14)\n",
    "weighted_log_loss(y_fit, y_pred, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
